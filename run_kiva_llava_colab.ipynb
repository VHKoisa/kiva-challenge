{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749b8cde",
   "metadata": {},
   "source": [
    "# Running KiVA Benchmark with LLaVA (Memory Optimized)\n",
    "\n",
    "This notebook runs the KiVA benchmark using LLaVA model with memory optimizations in Google Colab.\n",
    "\n",
    "First, make sure you're using a GPU runtime:\n",
    "- Runtime > Change runtime type > GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663eb0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c14b44",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "Install required packages and clone the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision transformers pillow pandas\n",
    "!pip install bitsandbytes accelerate\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/VHKoisa/kiva-challenge.git\n",
    "%cd kiva-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72301167",
   "metadata": {},
   "source": [
    "## 2. Memory Management Setup\n",
    "\n",
    "Configure memory management settings for optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Configure PyTorch memory management\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "\n",
    "def cleanup_memory():\n",
    "    \"\"\"Clean up GPU memory\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e0a61e",
   "metadata": {},
   "source": [
    "## 3. Run KiVA Benchmark\n",
    "\n",
    "Run the benchmark with memory-optimized settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbbb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the run\n",
    "concept = \"2DRotation\"  # Options: 2DRotation, Colour, Resize, Reflect, Counting\n",
    "max_trials = 5\n",
    "max_regenerations = 1\n",
    "batch_size = 1\n",
    "\n",
    "# Run the benchmark\n",
    "!python chat_systems/chat_system_single_image_kiva_reduced.py \\\n",
    "    --model llava \\\n",
    "    --concept {concept} \\\n",
    "    --max_trials {max_trials} \\\n",
    "    --max_regenerations {max_regenerations} \\\n",
    "    --batch_size {batch_size}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03fb28",
   "metadata": {},
   "source": [
    "## 4. View Results Side by Side\n",
    "\n",
    "Display and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36964255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "def display_images_side_by_side(img_paths, titles=None, figsize=(15, 5)):\n",
    "    \"\"\"Display multiple images side by side\"\"\"\n",
    "    n = len(img_paths)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize)\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (ax, img_path) in enumerate(zip(axes, img_paths)):\n",
    "        img = Image.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if titles and i < len(titles):\n",
    "            ax.set_title(titles[i])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get the results directory\n",
    "results_dir = f\"output/single_image/output_llava/{concept}/{concept}_stitch\"\n",
    "image_files = sorted(glob.glob(f\"{results_dir}/*.jpg\"))\n",
    "\n",
    "if image_files:\n",
    "    print(f\"Found {len(image_files)} result images\")\n",
    "    # Display first result\n",
    "    display_images_side_by_side([image_files[0]], [\"Sample Result\"])\n",
    "else:\n",
    "    print(\"No result images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45e4f0",
   "metadata": {},
   "source": [
    "## 5. Analyze Performance\n",
    "\n",
    "View accuracy and performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd84333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load results CSV\n",
    "results_file = f\"output/single_image/output_llava/{concept}/{concept}+90.csv\"\n",
    "if os.path.exists(results_file):\n",
    "    df = pd.read_csv(results_file)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = {\n",
    "        'Cross-Domain': (df['MCResponse#1'] == '1').mean(),\n",
    "        'Within-Domain': (df['MCResponse#2'] == '1').mean(),\n",
    "        'Extrapolation': (df['MCResponse#3'] == '1').mean()\n",
    "    }\n",
    "    \n",
    "    print(\"Accuracy Results:\")\n",
    "    for task, acc in accuracy.items():\n",
    "        print(f\"{task}: {acc:.2%}\")\n",
    "else:\n",
    "    print(\"No results file found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463ac6c9",
   "metadata": {},
   "source": [
    "## 6. Memory Cleanup\n",
    "\n",
    "Clean up resources after running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup\n",
    "cleanup_memory()\n",
    "\n",
    "# Print final memory status\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Available GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
