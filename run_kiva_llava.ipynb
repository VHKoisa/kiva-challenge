{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab823eb",
   "metadata": {},
   "source": [
    "# Running KiVA Benchmark with LLaVA\n",
    "\n",
    "This notebook sets up and runs the KiVA benchmark using the LLaVA (Large Language and Vision Assistant) model.\n",
    "\n",
    "Make sure you're running this notebook with a GPU runtime in Colab:\n",
    "- Runtime > Change runtime type > GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e081376a",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's install the required packages and clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision transformers pillow\n",
    "!pip install bitsandbytes accelerate\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb285d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the KiVA repository\n",
    "!git clone https://github.com/VHKoisa/kiva-challenge.git\n",
    "%cd kiva-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0a5163",
   "metadata": {},
   "source": [
    "## 2. Import Required Modules and Setup Model\n",
    "\n",
    "Now we'll import the necessary modules and set up the LLaVA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fa86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import LlavaForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Set PyTorch memory management\n",
    "torch.cuda.empty_cache()\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# Enable memory efficient attention\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['ATTENTION_IMPLEMENTATION'] = 'flash_attention_2'\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Print available GPU memory\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llava_model():\n",
    "    # Use 7B model instead of 13B\n",
    "    model_id = \"llava-hf/llava-1.5-7b-hf\"\n",
    "    \n",
    "    # Load model with memory optimizations\n",
    "    model = LlavaForConditionalGeneration.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16,\n",
    "        load_in_8bit=True,  # Enable 8-bit quantization\n",
    "        device_map=\"auto\",  # Automatically manage memory\n",
    "        max_memory={0: \"4GB\"},  # Limit GPU memory usage\n",
    "        low_cpu_mem_usage=True\n",
    "    )\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    processor.image_processor.do_center_crop = False\n",
    "    \n",
    "    # Clear cache after loading\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return model, processor\n",
    "\n",
    "# Load the model\n",
    "model, processor = load_llava_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4253777",
   "metadata": {},
   "source": [
    "## 3. Run KiVA Benchmark\n",
    "\n",
    "Now we can run the KiVA benchmark using the single image format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a929ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the parameters\n",
    "concept = \"2DRotation\"  # You can change this to: Colour, Resize, Reflect, or Counting\n",
    "difficulty = \"kiva\"     # or \"kiva-adults\" for harder version\n",
    "\n",
    "# Import and run the chat system\n",
    "from chat_systems.chat_system_single_image_kiva import main\n",
    "\n",
    "# Run the benchmark\n",
    "results = main(concept=concept, model=\"llava\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea4985",
   "metadata": {},
   "source": [
    "## 4. View Results\n",
    "\n",
    "The results will show the model's performance on the benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results summary\n",
    "print(f\"Results for {concept} concept:\")\n",
    "print(f\"Accuracy: {results['accuracy']:.2f}%\")\n",
    "print(\"\\nDetailed results:\")\n",
    "for trial in results['trials']:\n",
    "    print(f\"Trial {trial['id']}: {trial['result']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
